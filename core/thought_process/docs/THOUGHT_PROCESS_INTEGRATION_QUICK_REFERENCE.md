# Thought Process Framework - Integration Quick Reference

**Quick Guide to Implement Language Teaching Thought Processes**

---

## ğŸ¯ The Complete Picture (One Diagram)

```
STUDENT INPUT (Speech/Text)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ORCHESTRATOR SERVICE                        â”‚
â”‚  (src/services/orchestrator/service.py)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 1. Load System Prompt
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SYSTEM_PROMPT_LANGUAGE_TEACHING.md                â”‚
â”‚                                                      â”‚
â”‚  - Context: Learning environment                   â”‚
â”‚  - Language: [Portuguese, Spanish, etc.]           â”‚
â”‚  - Level: [A1, A2, B1, B2, C1, C2]                 â”‚
â”‚  - Instructs 9 Thought Processes                   â”‚
â”‚  - Specifies JSON output format                    â”‚
â”‚  - Guides pedagogy (RECAST, SCAFFOLDING, etc.)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 2. Send to LLM
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LLM SERVICE                                  â”‚
â”‚  (external_llm or llm service)                      â”‚
â”‚                                                      â”‚
â”‚  Receives:                                          â”‚
â”‚  - System Prompt (with Thought Process instructions)â”‚
â”‚  - Student input                                    â”‚
â”‚                                                      â”‚
â”‚  Generates:                                         â”‚
â”‚  - Main Response (conversational)                   â”‚
â”‚  - Response Metadata (9 JSON Thought Processes)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 3. Process Output
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPONSE METADATA & THOUGHT PROCESS FRAMEWORK       â”‚
â”‚  (RESPONSE_METADATA_AND_THOUGHT_PROCESS_            â”‚
â”‚   FRAMEWORK.md)                                      â”‚
â”‚                                                      â”‚
â”‚  Validates & Structures:                            â”‚
â”‚  - Process 1: Error Detection                       â”‚
â”‚  - Process 2: Grammar Analysis                      â”‚
â”‚  - Process 3: Vocabulary Assessment                 â”‚
â”‚  - Process 4: Pedagogical Strategy                  â”‚
â”‚  - Process 5: Conversation Flow                     â”‚
â”‚  - Process 6: Pronunciation Evaluation              â”‚
â”‚  - Process 7: Learning Progress                     â”‚
â”‚  - Process 8: Cultural Context                      â”‚
â”‚  - Process 9: Learning Recommendation               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 4. Serialize
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STREAMING_RESPONSE_MODELS                          â”‚
â”‚  (src/core/streaming_response_models.py)            â”‚
â”‚                                                      â”‚
â”‚  Pydantic models for type-safe JSON:               â”‚
â”‚  - LatencyMetrics                                   â”‚
â”‚  - ComponentOutputsResponse                         â”‚
â”‚  - StreamingConversationResponse                    â”‚
â”‚  - NDJSON Format (one JSON per line)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 5. Stream Response
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API GATEWAY                                         â”‚
â”‚  (src/services/api_gateway/routers/process.py)      â”‚
â”‚                                                      â”‚
â”‚  /stream/process endpoint                           â”‚
â”‚  Returns: NDJSON stream                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ 6. Display to User
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIENT SDK (TypeScript)                            â”‚
â”‚  (client-sdk/                                        â”‚
â”‚                                                      â”‚
â”‚  Shows to student/teacher:                          â”‚
â”‚  - Main Response (conversational)                   â”‚
â”‚  - Latency Metrics (performance)                    â”‚
â”‚  - Thought Processes (transparency)                 â”‚
â”‚  - Learning Recommendations (guidance)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
              STUDENT SEES
         Language Learning Platform
          with Full Transparency
```

---

## ğŸ“‹ Implementation Checklist

### Step 1: System Prompt Setup âœ…
- [ ] Read: `SYSTEM_PROMPT_LANGUAGE_TEACHING.md`
- [ ] Understand: Why it's critical
- [ ] Customize: Fill in language and level placeholders
- [ ] Store: Make accessible to Orchestrator

### Step 2: Orchestrator Integration âœ…
- [ ] Location: `src/services/orchestrator/service.py`
- [ ] Update: `process_conversation()` method
- [ ] Add: Load and customize system prompt before LLM call
- [ ] Pass: `system_prompt` parameter to LLM

```python
# In orchestrator/routes.py
async def process_conversation(request: ConversationRequest):
    # Load and customize system prompt
    SYSTEM_PROMPT = load_file("SYSTEM_PROMPT_LANGUAGE_TEACHING.md")
    SYSTEM_PROMPT = customize_prompt(
        SYSTEM_PROMPT,
        language="Portuguese",
        level=student_level,
        session_number=turn_number
    )

    # Call LLM with system prompt
    response = await self.llm_service.generate(
        system_prompt=SYSTEM_PROMPT,  # â† CRITICAL
        user_input=request.audio_text,
        session_id=request.session_id
    )

    # Response should contain:
    # - llm_response (main response)
    # - response_metadata (9 Thought Processes)
    return response
```

### Step 3: Response Validation âœ…
- [ ] Verify: All 9 Thought Processes are generated
- [ ] Validate: JSON structure matches framework
- [ ] Check: "analysis" field present in each process
- [ ] Test: With different student levels (A1, A2, B1, B2)

### Step 4: Streaming Setup âœ…
- [ ] Location: `src/services/api_gateway/routers/process.py`
- [ ] Endpoint: `/stream/process`
- [ ] Format: NDJSON (one JSON object per line)
- [ ] Serialization: Use `StreamingResponseBuilder.to_ndjson()`

### Step 5: Client Integration âœ…
- [ ] Parse NDJSON stream (one JSON per line)
- [ ] Display main response to user
- [ ] Show latency metrics
- [ ] Optionally display Thought Processes (transparency)
- [ ] Use learning recommendations for follow-up

### Step 6: Testing âœ…
- [ ] Run: `pytest tests/integration/test_perceived_latency_integration.py -v`
- [ ] Verify: All 9 processes in response
- [ ] Test: With actual student inputs (errors, complexities)
- [ ] Monitor: Latency (should be < 1200ms total)

### Step 7: Deployment âœ…
- [ ] Stage: Deploy to staging environment
- [ ] Monitor: Check thought process generation
- [ ] Metrics: Set up dashboards for performance
- [ ] Production: Deploy with monitoring active

---

## ğŸ”„ Data Flow Examples

### Example 1: A2 Student Makes Grammar Error

```
INPUT:
  User: "Eu vai para praia"  [Grammar error: vaiâ†’vou]

SYSTEM PROMPT GUIDES:
  - Analyze error
  - Choose pedagogy: RECAST (implicit correction)
  - Generate 9 Thought Processes
  - Output JSON with process details

LLM RESPONSE:
{
  "llm_response": "Ah, vocÃª VAI para a praia! Que legal!",
  "response_metadata": {
    "thought_process": {
      "processes": [
        {
          "id": 1,
          "name": "Error Detection",
          "content": {
            "errors_found": [
              {
                "type": "grammar",
                "error": "vai (3rd person) â†’ vou (1st person)",
                "severity": "major"
              }
            ]
          }
        },
        {
          "id": 4,
          "name": "Pedagogical Strategy",
          "content": {
            "strategy": "recast",
            "implementation": "Naturally repeat correct form",
            "learning_objective": "Verb conjugation awareness"
          }
        },
        ...  // Processes 2,3,5,6,7,8,9
      ]
    }
  }
}

CLIENT DISPLAYS:
  Response: "Ah, vocÃª VAI para a praia! Que legal!"

  Optional metadata panel:
  - Error detected: "vai" should be "vou"
  - Teaching method: RECAST (implicit correction)
  - Learning objective: Verb conjugation
```

### Example 2: B1 Student Uses Complex Structure

```
INPUT:
  User: "Enquanto eu estava na praia, vi meu amigo que nÃ£o via hÃ¡ muito tempo"

SYSTEM PROMPT GUIDES:
  - Recognize: Advanced past narrative
  - Choose pedagogy: EXPANSION + PROMPTING
  - Generate 9 processes with deeper analysis

LLM RESPONSE:
{
  "llm_response": "Que encontro especial! Como se sentiram ao se reencontrarem?",
  "response_metadata": {
    "thought_process": {
      "processes": [
        {
          "id": 2,
          "name": "Grammar Analysis",
          "content": {
            "sentence_structure": "Complex with temporal subordination",
            "main_verb": "Past continuous + simple",
            "grammar_score": 1.0
          }
        },
        {
          "id": 4,
          "name": "Pedagogical Strategy",
          "content": {
            "strategy": "expansion",
            "implementation": "Expand topic, ask for more details",
            "learning_objective": "Develop narrative skills"
          }
        },
        {
          "id": 9,
          "name": "Learning Recommendation",
          "content": {
            "recommended_practice": "Temporal connectors",
            "focus": "entÃ£o, depois, enquanto",
            "priority": "medium"
          }
        },
        ...  // Other 6 processes
      ]
    }
  }
}
```

---

## ğŸ“Š Files You Need to Know

| File | Purpose | Status |
|------|---------|--------|
| `SYSTEM_PROMPT_LANGUAGE_TEACHING.md` | **Instructions for LLM** | âœ… Ready |
| `RESPONSE_METADATA_AND_THOUGHT_PROCESS_FRAMEWORK.md` | Define 9 processes & structure | âœ… Ready |
| `src/core/streaming_response_models.py` | Pydantic models | âœ… Ready |
| `src/core/perceived_latency_manager.py` | Latency tracking | âœ… Ready |
| `orchestrator/routes.py` | **INTEGRATE PROMPT HERE** | ğŸ“ Action needed |
| `api_gateway/routers/process.py` | Streaming endpoint | ğŸ“ Action needed |
| `client-sdk/` | Display responses | ğŸ“ Action needed |
| `tests/integration/test_perceived_latency_integration.py` | Validation | âœ… Ready |

---

## âš ï¸ Critical Success Factors

### Without System Prompt
âŒ LLM won't know about Thought Processes
âŒ Response Metadata won't be generated
âŒ System acts as general chatbot, not language teacher
âŒ 9 Processes missing
âŒ Pedagogical strategies not applied

### With System Prompt (Properly Integrated)
âœ… LLM understands learning context
âœ… All 9 Thought Processes generated automatically
âœ… System acts as intelligent language teacher
âœ… Students see transparent reasoning
âœ… Pedagogical strategies applied implicitly
âœ… Learning recommendations provided

---

## ğŸš€ Immediate Next Steps (Priority Order)

1. **Read** the System Prompt: `SYSTEM_PROMPT_LANGUAGE_TEACHING.md`
2. **Understand** Why it's critical (System Prompt Integration section)
3. **Integrate** into Orchestrator (load and pass to LLM)
4. **Test** with sample student inputs
5. **Verify** all 9 processes are generated
6. **Deploy** to staging
7. **Monitor** and refine

---

## ğŸ”— See Also

- `SYSTEM_PROMPT_LANGUAGE_TEACHING.md` - **READ THIS FIRST** âš ï¸
- `RESPONSE_METADATA_AND_THOUGHT_PROCESS_FRAMEWORK.md` - Detailed process definitions
- `PERCEIVED_LATENCY_SYSTEM_INTEGRATION.md` - Latency framework
- `PERCEIVED_LATENCY_INTEGRATION_SUMMARY.md` - Overview

---

**Status:** ğŸŸ¢ **Complete and Ready for Integration**

The foundation is ready. The critical piece is ensuring the System Prompt is properly integrated into the Orchestrator's LLM pipeline.

**Version:** 1.0
**Last Updated:** October 26, 2025
